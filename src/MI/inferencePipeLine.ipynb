{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "dQbRCMu71_z9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qq7LBICM1u8n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import FastICA\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import iirnotch, filtfilt, butter , coherence, csd, welch, hilbert\n",
        "import scipy.signal as signal\n",
        "from scipy.stats import kurtosis , skew"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Independent Component Analysis (ICA) helper\n",
        "# ---------------------------------------------------------------------------\n",
        "def apply_ica(data):\n",
        "    data = np.asarray(data)                           # ensure ndarray\n",
        "    if data.ndim == 1:                                # reshape 1‑D → 2‑D\n",
        "        data = data[:, None]\n",
        "\n",
        "    ica = FastICA(                                    # ICA model\n",
        "        n_components=data.shape[1],\n",
        "        random_state=42,\n",
        "        max_iter=2000,\n",
        "        tol=1e-5\n",
        "    )\n",
        "\n",
        "    S = ica.fit_transform(data)                       # sources\n",
        "    k = np.abs(kurtosis(S, axis=0, fisher=False))     # kurtosis per source\n",
        "    S[:, k > 5] = 0                                   # suppress artifactual comps\n",
        "    cleaned = ica.inverse_transform(S)                # back‑project\n",
        "    return cleaned.squeeze()                          # drop singleton dims\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# End‑to‑end preprocessing + feature extraction\n",
        "# ---------------------------------------------------------------------------\n",
        "def preprocessing_and_loading(\n",
        "    subjects_of_train,\n",
        "    path_of_MI_diret_train,\n",
        "    output_csv=\"MI_features.csv\"\n",
        "):\n",
        "    \"\"\"Pipeline: load raw MI data → preprocess → extract features → CSV.\n",
        "\n",
        "    Each row in the resulting CSV corresponds to one trial.\n",
        "    \"\"\"\n",
        "    # ----------------------------- constants --------------------------------\n",
        "    fs = 250                          # sampling frequency (Hz)\n",
        "    baseline_end = fs                 # 1‑s baseline (first 250 samples)\n",
        "    fbcsp_bands = [                   # FBCSP sub‑bands (Hz)\n",
        "        (8, 12), (12, 16), (16, 20),\n",
        "        (20, 24), (24, 28), (28, 32)\n",
        "    ]\n",
        "\n",
        "    # -------------------- helper: band‑power (FFT) --------------------------\n",
        "    def bandpower(sig, f_lo, f_hi):\n",
        "        \"\"\"Relative power within [f_lo, f_hi] using periodogram.\"\"\"\n",
        "        freqs = np.fft.rfftfreq(len(sig), 1 / fs)\n",
        "        pxx = np.abs(np.fft.rfft(sig)) ** 2\n",
        "        band_mask = (freqs >= f_lo) & (freqs <= f_hi)\n",
        "        return np.sum(pxx[band_mask]) / len(sig)\n",
        "\n",
        "    # ----------------------------- main loop --------------------------------\n",
        "    rows, X_all = [], []\n",
        "\n",
        "    for sbj in subjects_of_train:\n",
        "        # Notch + band‑pass filters\n",
        "        f0, Q = 50, 30                               # notch (50 Hz line noise)\n",
        "        b_notch, a_notch = iirnotch(f0, Q, fs)\n",
        "        b_bp, a_bp = butter(4, [8 / (fs / 2), 30 / (fs / 2)], btype=\"band\")\n",
        "\n",
        "        sbj_path = os.path.join(path_of_MI_diret_train, sbj)\n",
        "\n",
        "        for sess in os.listdir(sbj_path):\n",
        "            # Assumes a single CSV per session directory\n",
        "            csv_path = os.path.join(sbj_path, sess,\n",
        "                                    os.listdir(os.path.join(sbj_path, sess))[0])\n",
        "            data_df = pd.read_csv(csv_path)\n",
        "\n",
        "            for tr in range(1, 11):                  # 10 trials per session\n",
        "                # ------------------------------------------------------------------\n",
        "                # 1) Segment & ICA cleaning\n",
        "                # ------------------------------------------------------------------\n",
        "                seg = data_df.iloc[2250 * (tr - 1):2250 * tr, 1:9].to_numpy()\n",
        "                seg = apply_ica(seg)\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 2) Filtering (notch → band‑pass)\n",
        "                # ------------------------------------------------------------------\n",
        "                c3 = filtfilt(b_notch, a_notch, seg[:, 1] - seg[:, 1].mean())\n",
        "                cz = filtfilt(b_notch, a_notch, seg[:, 2] - seg[:, 2].mean())\n",
        "                c4 = filtfilt(b_notch, a_notch, seg[:, 3] - seg[:, 3].mean())\n",
        "\n",
        "                for ch in range(seg.shape[1]):                       # band‑pass all\n",
        "                    seg[:, ch] = filtfilt(b_bp, a_bp, seg[:, ch])\n",
        "\n",
        "                c3 = filtfilt(b_bp, a_bp, c3)\n",
        "                cz = filtfilt(b_bp, a_bp, cz)\n",
        "                c4 = filtfilt(b_bp, a_bp, c4)\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 3) Baseline correction (ERD/ERS)\n",
        "                # ------------------------------------------------------------------\n",
        "                c3 -= c3[:baseline_end].mean()\n",
        "                cz -= cz[:baseline_end].mean()\n",
        "                c4 -= c4[:baseline_end].mean()\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 4) Time‑domain features\n",
        "                # ------------------------------------------------------------------\n",
        "                row = {\n",
        "                    \"subject_id\": sbj,\n",
        "                    \"session_id\": sess,\n",
        "                    \"trial_id\": tr,\n",
        "                    # basic stats (C3)\n",
        "                    \"min_val_C3\":   float(c3.min()),\n",
        "                    \"max_val_C3\":   float(c3.max()),\n",
        "                    \"mean_val_C3\":  float(c3.mean()),\n",
        "                    \"energy_C3\":    float(np.sum(c3 ** 2)),\n",
        "                    # basic stats (C4)\n",
        "                    \"min_val_C4\":   float(c4.min()),\n",
        "                    \"max_val_C4\":   float(c4.max()),\n",
        "                    \"mean_val_C4\":  float(c4.mean()),\n",
        "                    \"energy_C4\":    float(np.sum(c4 ** 2))\n",
        "                }\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 5) ERD/ERS (8–30 Hz band power)\n",
        "                # ------------------------------------------------------------------\n",
        "                base_c3 = bandpower(c3[:baseline_end], 8, 30)\n",
        "                task_c3 = bandpower(c3[baseline_end:], 8, 30)\n",
        "                base_c4 = bandpower(c4[:baseline_end], 8, 30)\n",
        "                task_c4 = bandpower(c4[baseline_end:], 8, 30)\n",
        "\n",
        "                row.update({\n",
        "                    \"alpha_C3\":  float(bandpower(c3, 8, 12)),\n",
        "                    \"alpha_C4\":  float(bandpower(c4, 8, 12)),\n",
        "                    \"erd_C3_pct\": 10 * np.log10(task_c3 / base_c3) if base_c3 else 0.0,\n",
        "                    \"erd_C4_pct\": 10 * np.log10(task_c4 / base_c4) if base_c4 else 0.0\n",
        "                })\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 6) Connectivity: coherence / imaginary coherence / PLV\n",
        "                # ------------------------------------------------------------------\n",
        "                f_coh, coh = signal.coherence(c3, c4, fs=fs, nperseg=fs * 2)\n",
        "                mu_band = (f_coh >= 8) & (f_coh <= 30)\n",
        "                coh_mu = float(coh[mu_band].mean()) if mu_band.any() else 0.0\n",
        "\n",
        "                f_csd, Pxy = signal.csd(c3, c4, fs=fs, nperseg=fs * 2)\n",
        "                f_pxx, Pxx = signal.welch(c3, fs=fs, nperseg=fs * 2)\n",
        "                f_pyy, Pyy = signal.welch(c4, fs=fs, nperseg=fs * 2)\n",
        "                imcoh = np.imag(Pxy) / np.sqrt(Pxx * Pyy)\n",
        "                imcoh_mu = float(imcoh[(f_csd >= 8) & (f_csd <= 30)].mean())\n",
        "\n",
        "                phi = np.angle(signal.hilbert(c3)) - np.angle(signal.hilbert(c4))\n",
        "                plv_val = float(np.abs(np.exp(1j * phi).mean()))\n",
        "\n",
        "                row.update({\n",
        "                    \"coh_C3C4_mu\":   coh_mu,\n",
        "                    \"imcoh_C3C4_mu\": imcoh_mu,\n",
        "                    \"plv_C3C4\":      plv_val\n",
        "                })\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 7) Higher‑order stats\n",
        "                # ------------------------------------------------------------------\n",
        "                row.update({\n",
        "                    \"range_C3\": float(np.ptp(c3)),\n",
        "                    \"std_C3\":   float(c3.std()),\n",
        "                    \"skew_C3\":  float(skew(c3)),\n",
        "                    \"kurt_C3\":  float(kurtosis(c3)),\n",
        "                    \"range_C4\": float(np.ptp(c4)),\n",
        "                    \"std_C4\":   float(c4.std()),\n",
        "                    \"skew_C4\":  float(skew(c4)),\n",
        "                    \"kurt_C4\":  float(kurtosis(c4))\n",
        "                })\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 8) Frequency‑domain features (whole 0–40 Hz spectrum)\n",
        "                # ------------------------------------------------------------------\n",
        "                freqs = np.fft.rfftfreq(len(c3), 1 / fs)\n",
        "                mask40 = freqs <= 40\n",
        "                power_c3 = np.abs(np.fft.rfft(c3)) ** 2\n",
        "                power_c4 = np.abs(np.fft.rfft(c4)) ** 2\n",
        "\n",
        "                mean_f_c3 = np.sum(freqs * power_c3) / np.sum(power_c3)\n",
        "                mean_f_c4 = np.sum(freqs * power_c4) / np.sum(power_c4)\n",
        "                bw_c3 = np.sqrt(np.sum(((freqs - mean_f_c3) ** 2) * power_c3) / np.sum(power_c3))\n",
        "                bw_c4 = np.sqrt(np.sum(((freqs - mean_f_c4) ** 2) * power_c4) / np.sum(power_c4))\n",
        "                beta_c3 = np.sum(power_c3[(freqs >= 13) & (freqs <= 30)]) / len(c3)\n",
        "                beta_c4 = np.sum(power_c4[(freqs >= 13) & (freqs <= 30)]) / len(c4)\n",
        "\n",
        "                row.update({\n",
        "                    \"peak_freq_C3\":   float(freqs[np.argmax(power_c3)]),\n",
        "                    \"peak_freq_C4\":   float(freqs[np.argmax(power_c4)]),\n",
        "                    \"mean_freq_C3\":   float(mean_f_c3),\n",
        "                    \"mean_freq_C4\":   float(mean_f_c4),\n",
        "                    \"bw_C3\":          float(bw_c3),\n",
        "                    \"bw_C4\":          float(bw_c4),\n",
        "                    \"beta_power_C3\":  float(beta_c3),\n",
        "                    \"beta_power_C4\":  float(beta_c4),\n",
        "                    \"psd_mean_C3\":    float(Pxx.mean()),\n",
        "                    \"psd_mean_C4\":    float(Pyy.mean())\n",
        "                })\n",
        "\n",
        "                # ------------------------------------------------------------------\n",
        "                # 9) Filter bank CSP‑like band powers\n",
        "                # ------------------------------------------------------------------\n",
        "                for lo, hi in fbcsp_bands:\n",
        "                    mask = (freqs >= lo) & (freqs < hi)\n",
        "                    row[f\"fbcsp_{lo}_{hi}_C3\"] = float(np.sum(power_c3[mask]) / len(c3))\n",
        "                    row[f\"fbcsp_{lo}_{hi}_C4\"] = float(np.sum(power_c4[mask]) / len(c4))\n",
        "\n",
        "                # Accumulate\n",
        "                rows.append(row)\n",
        "                X_all.append(np.stack([c3, cz, c4], axis=1))\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 10) Common Spatial Patterns (CSP) on concatenated trials\n",
        "    # ----------------------------------------------------------------------\n",
        "    if X_all:\n",
        "        X_all_arr = np.array(X_all)\n",
        "        cov = np.mean([np.cov(trial.T) for trial in X_all_arr], axis=0)\n",
        "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
        "        n_filt = min(4, eigvecs.shape[1])\n",
        "        W = eigvecs[:, eigvals.argsort()[::-1][:n_filt]]\n",
        "\n",
        "        for row, trial in zip(rows, X_all_arr):\n",
        "            Z = trial @ W                         # spatially‑filtered signals\n",
        "            var = np.var(Z, axis=0)\n",
        "            logvar = np.log(var / var.sum())      # normalized log‑variance\n",
        "            for k, v in enumerate(logvar, start=1):\n",
        "                row[f\"csp{k}\"] = float(v)\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 11) Save to CSV\n",
        "    # ----------------------------------------------------------------------\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "SoSJWk1h1w90"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#put the path to the data set\n",
        "Path_of_the_data_set=\"/content/aic/MI/test\"\n",
        "the_data_set=[]\n",
        "subjects_of_data = os.listdir(Path_of_the_data_set)\n",
        "train_Data = preprocessing_and_loading(subjects_of_data,Path_of_the_data_set,\"MI_features_train.csv\")"
      ],
      "metadata": {
        "id": "NEAVmni14cZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "rM91fBZy2Fw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  load the model , scalar and the features of the model\n",
        "*   scale all the the data\n",
        "*   select the features from the scaled data\n",
        "*   predict the data using the model\n",
        "\n"
      ],
      "metadata": {
        "id": "hXX5SkeI58Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "#full feature list\n",
        "feature_names = ['min_val_C3', 'max_val_C3', 'mean_val_C3', 'energy_C3', 'min_val_C4', 'max_val_C4', 'mean_val_C4',\n",
        "                 'energy_C4', 'alpha_C3', 'alpha_C4', 'erd_C3_pct', 'erd_C4_pct', 'coh_C3C4_mu', 'imcoh_C3C4_mu',\n",
        "                 'plv_C3C4', 'range_C3', 'std_C3', 'skew_C3', 'kurt_C3', 'range_C4', 'std_C4', 'skew_C4', 'kurt_C4',\n",
        "                 'peak_freq_C3', 'peak_freq_C4', 'mean_freq_C3', 'mean_freq_C4', 'bw_C3', 'bw_C4', 'beta_power_C3',\n",
        "                 'beta_power_C4', 'psd_mean_C3', 'psd_mean_C4', 'fbcsp_8_12_C3', 'fbcsp_8_12_C4', 'fbcsp_12_16_C3',\n",
        "                 'fbcsp_12_16_C4', 'fbcsp_16_20_C3', 'fbcsp_16_20_C4', 'fbcsp_20_24_C3', 'fbcsp_20_24_C4',\n",
        "                 'fbcsp_24_28_C3', 'fbcsp_24_28_C4', 'fbcsp_28_32_C3', 'fbcsp_28_32_C4', 'csp1', 'csp2', 'csp3']\n",
        "\n",
        "# Inverse label mapping\n",
        "inverse_label_map = {0: 'Left', 1: 'Right'}\n",
        "\n",
        "# Load components\n",
        "model = joblib.load(\"best_model.pkl\")\n",
        "scaler = joblib.load(\"scaler_for_best_features2.pkl\")\n",
        "best_features = joblib.load(\"selected_feature_list2.pkl\")\n",
        "\n",
        "# Step 1: Scale full Data (must have all 48 columns, in same order)\n",
        "X_scaled_full = scaler.transform(the_data_set[feature_names])\n",
        "\n",
        "# Step 2: Wrap scaled data back into a DataFrame for column access\n",
        "X_scaled_df = pd.DataFrame(X_scaled_full, columns=feature_names)\n",
        "\n",
        "# Step 3: Select only best features (now scaled)\n",
        "X_new_scaled = X_scaled_df[best_features]\n",
        "# Step 4: Predict\n",
        "y_pred = model.predict(X_new_scaled)\n",
        "y_proba = model.predict_proba(X_new_scaled)\n",
        "\n",
        "\n",
        "\n",
        "# Step 5: Decode prediction\n",
        "decoded_preds = [inverse_label_map[p] for p in y_pred]\n",
        "# Step 6: Show results\n",
        "for i in range(len(y_pred)):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Predicted class: {y_pred[i]} ({decoded_preds[i]})\")\n",
        "    print(f\"  Class probabilities: {y_proba[i]}\")\n",
        "    print()\n",
        "results_df = pd.DataFrame({\n",
        "\n",
        "    \"label\": decoded_preds,\n",
        "\n",
        "})\n",
        "\n"
      ],
      "metadata": {
        "id": "NzIHoGDx1zvk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}